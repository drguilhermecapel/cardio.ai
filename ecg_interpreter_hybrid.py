
import numpy as np
import tensorflow as tf
from hybrid_ecg_digitizer import HybridECGDigitizer
from typing import Union, Dict, List, Optional
import os
import json
from datetime import datetime

class ECGInterpreterHybrid:
    """
    Interpretador de ECG com digitizer h√≠brido para m√°xima compatibilidade
    """

    def __init__(self, model_path: str, config: Optional[Dict] = None):
        """
        Inicializa interpretador

        Args:
            model_path: Caminho para o modelo
            config: Configura√ß√µes opcionais
        """
        # Configura√ß√µes padr√£o
        self.config = {
            'target_length': 1000,
            'verbose': True,
            'save_digitized': False,
            'quality_threshold': 0.5
        }
        if config:
            self.config.update(config)

        # Carregar modelo
        print(f"üìä Carregando modelo de {model_path}...")
        self.model = tf.keras.models.load_model(model_path)

        # Inicializar digitizer h√≠brido
        self.digitizer = HybridECGDigitizer(
            target_length=self.config['target_length'],
            verbose=self.config['verbose']
        )

        # Classes do modelo (ajuste conforme necess√°rio)
        self.class_names = [
            'Normal', 'AF', 'I-AVB', 'LBBB', 'RBBB',
            'PAC', 'PVC', 'STD', 'STE'
        ]

        # Estat√≠sticas
        self.stats = {
            'total_processed': 0,
            'successful': 0,
            'failed': 0,
            'methods_used': {}
        }

    def analyze(self, input_source: Union[str, np.ndarray],
                save_report: bool = False) -> Dict:
        """
        Analisa ECG com relat√≥rio detalhado

        Args:
            input_source: Arquivo ou array numpy
            save_report: Se deve salvar relat√≥rio JSON

        Returns:
            Dicion√°rio com resultados completos
        """
        start_time = datetime.now()

        try:
            # Digitalizar se necess√°rio
            if isinstance(input_source, str):
                digitization_result = self.digitizer.digitize(input_source)
                ecg_data = digitization_result['data']
                metadata = digitization_result
            else:
                ecg_data = input_source
                metadata = {'method': 'direct_array', 'quality': {'score': 1.0}}

            # Validar qualidade
            if metadata['quality']['score'] < self.config['quality_threshold']:
                return self._create_error_response(
                    "Qualidade de digitaliza√ß√£o insuficiente",
                    metadata
                )

            # Preparar para modelo
            ecg_input = self._prepare_for_model(ecg_data)

            # Predi√ß√£o
            predictions = self.model.predict(ecg_input, verbose=0)

            # Processar resultados
            results = self._process_predictions(
                predictions[0],
                ecg_data,
                metadata
            )

            # Adicionar metadados
            results['processing_time'] = (datetime.now() - start_time).total_seconds()
            results['timestamp'] = datetime.now().isoformat()

            # Atualizar estat√≠sticas
            self._update_stats(True, metadata.get('method', 'unknown'))

            # Salvar relat√≥rio se solicitado
            if save_report:
                self._save_report(results)

            return results

        except Exception as e:
            self._update_stats(False, 'error')
            return self._create_error_response(str(e), {})

    def analyze_batch(self, file_list: List[str]) -> List[Dict]:
        """Analisa m√∫ltiplos ECGs"""
        results = []

        print(f"\nüìã Processando {len(file_list)} ECGs...")

        for i, file_path in enumerate(file_list):
            print(f"\n[{i+1}/{len(file_list)}] {os.path.basename(file_path)}")

            result = self.analyze(file_path)
            result['file'] = file_path
            results.append(result)

            # Resumo
            if result['success']:
                print(f"‚úÖ {result['diagnosis']} ({result['confidence']:.1%})")
            else:
                print(f"‚ùå {result['error']}")

        # Estat√≠sticas finais
        self._print_stats()

        return results

    def _prepare_for_model(self, ecg_data: np.ndarray) -> np.ndarray:
        """Prepara dados para o modelo"""
        # Adicionar dimens√£o batch
        if ecg_data.ndim == 2:
            ecg_data = np.expand_dims(ecg_data, axis=0)

        # Adicionar dimens√£o de canal se necess√°rio
        if ecg_data.ndim == 3 and self.model.input_shape[-1] == 1:
            ecg_data = np.expand_dims(ecg_data, axis=-1)

        return ecg_data

    def _process_predictions(self, predictions: np.ndarray,
                           ecg_data: np.ndarray,
                           metadata: Dict) -> Dict:
        """Processa predi√ß√µes com an√°lise detalhada"""
        # Top diagn√≥stico
        top_idx = np.argmax(predictions)
        top_conf = float(predictions[top_idx])

        # Todos os diagn√≥sticos
        all_predictions = {}
        for i, class_name in enumerate(self.class_names):
            all_predictions[class_name] = float(predictions[i])

        # Diagn√≥sticos significativos (>10%)
        significant = {k: v for k, v in all_predictions.items() if v > 0.1}

        # An√°lise adicional
        analysis = self._perform_additional_analysis(ecg_data)

        # Criar resposta completa
        result = {
            'success': True,
            'diagnosis': self.class_names[top_idx],
            'confidence': top_conf,
            'all_predictions': all_predictions,
            'significant_findings': significant,
            'digitization': {
                'method': metadata.get('method', 'unknown'),
                'quality_score': metadata.get('quality', {}).get('score', 0),
                'quality_issues': metadata.get('quality', {}).get('issues', [])
            },
            'ecg_analysis': analysis,
            'interpretation': self._generate_interpretation(
                self.class_names[top_idx],
                top_conf,
                significant
            ),
            'recommendations': self._generate_recommendations(
                self.class_names[top_idx],
                top_conf
            )
        }

        # Adicionar dados digitalizados se configurado
        if self.config['save_digitized']:
            result['digitized_data'] = ecg_data.tolist()

        return result

    def _perform_additional_analysis(self, ecg_data: np.ndarray) -> Dict:
        """An√°lise adicional do ECG"""
        analysis = {}

        # Frequ√™ncia card√≠aca estimada (usando lead II)
        lead_ii = ecg_data[1] if ecg_data.shape[0] > 1 else ecg_data[0]

        # Detectar picos R (simplificado)
        from scipy.signal import find_peaks
        peaks, _ = find_peaks(lead_ii, height=np.std(lead_ii))

        if len(peaks) > 1:
            # Assumindo 10 segundos de ECG
            samples_per_second = self.config['target_length'] / 10
            bpm = 60 / (avg_rr / samples_per_second)

            analysis['heart_rate_bpm'] = int(np.clip(bpm, 30, 200))
            analysis['rhythm_regularity'] = 1 - (np.std(rr_intervals) / avg_rr)
        else:
            analysis['heart_rate_bpm'] = 'N√£o detectado'
            analysis['rhythm_regularity'] = 'N√£o calculado'

        return analysis

    def _generate_interpretation(self, diagnosis: str,
                               confidence: float,
                               significant: Dict) -> str:
        """Gera interpreta√ß√£o textual"""
        interpretations = {
            'Normal': "ECG dentro dos par√¢metros normais",
            'AF': "Fibrila√ß√£o atrial detectada - ritmo irregular",
            'I-AVB': "Bloqueio atrioventricular de primeiro grau",
            'LBBB': "Bloqueio de ramo esquerdo",
            'RBBB': "Bloqueio de ramo direito",
            'PAC': "Contra√ß√£o atrial prematura",
            'PVC': "Contra√ß√£o ventricular prematura",
            'STD': "Depress√£o do segmento ST - poss√≠vel isquemia",
            'STE': "Eleva√ß√£o do segmento ST - poss√≠vel infarto agudo"
        }

        base_interp = interpretations.get(diagnosis, "Anormalidade detectada")

        # Adicionar n√≠vel de confian√ßa
        if confidence > 0.9:
            conf_text = "com alta confian√ßa"
        elif confidence > 0.7:
            conf_text = "com boa confian√ßa"
        else:
            conf_text = "com confian√ßa moderada - confirmar com especialista"

        interpretation = f"{base_interp} ({conf_text} - {confidence:.1%})"

        # Mencionar outros achados significativos
        other_findings = [k for k, v in significant.items()
                         if k != diagnosis and v > 0.2]

        if other_findings:
            interpretation += f"\n\nOutros achados poss√≠veis: {', '.join(other_findings)}"

        return interpretation

    def _generate_recommendations(self, diagnosis: str, confidence: float) -> List[str]:
        """Gera recomenda√ß√µes baseadas no diagn√≥stico"""
        urgent_conditions = ['AF', 'STE', 'STD']

        recommendations = []

        if diagnosis in urgent_conditions:
            recommendations.append("‚ö†Ô∏è Procurar atendimento m√©dico imediato")

        if confidence < 0.7:
            recommendations.append("üìã Repetir ECG para confirma√ß√£o")

        if diagnosis != 'Normal':
            recommendations.append("üë®‚Äç‚öïÔ∏è Consultar cardiologista para avalia√ß√£o completa")

        recommendations.append("üìÅ Manter registro deste ECG para compara√ß√µes futuras")

        return recommendations

    def _create_error_response(self, error_msg: str, metadata: Dict) -> Dict:
        """Cria resposta de erro padronizada"""
        return {
            'success': False,
            'error': error_msg,
            'digitization': metadata,
            'timestamp': datetime.now().isoformat()
        }

    def _update_stats(self, success: bool, method: str):
        """Atualiza estat√≠sticas"""
        self.stats['total_processed'] += 1

        if success:
            self.stats['successful'] += 1
            self.stats['methods_used'][method] = \
                self.stats['methods_used'].get(method, 0) + 1
        else:
            self.stats['failed'] += 1

    def _print_stats(self):
        """Imprime estat√≠sticas"""
        print(f"\nüìä Estat√≠sticas:")
        print(f"Total processado: {self.stats['total_processed']}")
        print(f"Sucesso: {self.stats['successful']} ({self.stats['successful']/self.stats['total_processed']*100:.1f}%)")
        print(f"Falhas: {self.stats['failed']}")

        if self.stats['methods_used']:
            print(f"\nM√©todos utilizados:")
            for method, count in self.stats['methods_used'].items():
                print(f"  {method}: {count}")

    def _save_report(self, results: Dict):
        """Salva relat√≥rio em JSON"""
        filename = f"ecg_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)

        print(f"üìÑ Relat√≥rio salvo: {filename}")
