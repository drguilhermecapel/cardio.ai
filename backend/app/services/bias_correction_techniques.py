# bias_correction_techniques.py
"""
T√©cnicas Avan√ßadas de Corre√ß√£o de Bias para Pesquisa
Implementa m√∫ltiplas estrat√©gias para mitigar bias do modelo PTB-XL
"""

import numpy as np
import logging
from typing import Dict, List, Any, Tuple, Optional
from scipy import stats
from sklearn.calibration import CalibratedClassifierCV
from sklearn.utils import resample

logger = logging.getLogger(__name__)

class BiasCorrector:
    """Implementa t√©cnicas avan√ßadas de corre√ß√£o de bias."""
    
    def __init__(self, num_classes: int = 71):
        self.num_classes = num_classes
        self.correction_methods = {}
        self.bias_statistics = {}
        self.calibration_curves = {}
        
    def analyze_bias_patterns(self, predictions: np.ndarray, true_labels: Optional[np.ndarray] = None) -> Dict[str, Any]:
        """
        Analisa padr√µes de bias nas predi√ß√µes do modelo.
        
        Args:
            predictions: Array de predi√ß√µes (N, num_classes)
            true_labels: Labels verdadeiros opcionais (N,)
            
        Returns:
            Dicion√°rio com an√°lise detalhada de bias
        """
        analysis = {
            'class_frequency': {},
            'prediction_entropy': [],
            'confidence_distribution': {},
            'bias_severity': {},
            'problematic_classes': []
        }
        
        # An√°lise de frequ√™ncia por classe
        predicted_classes = np.argmax(predictions, axis=1)
        unique, counts = np.unique(predicted_classes, return_counts=True)
        
        for class_id, count in zip(unique, counts):
            frequency = count / len(predictions)
            analysis['class_frequency'][int(class_id)] = frequency
            
            # Identificar classes com bias extremo (>30% das predi√ß√µes)
            if frequency > 0.3:
                analysis['problematic_classes'].append(int(class_id))
        
        # An√°lise de entropia (diversidade de predi√ß√µes)
        for i, pred in enumerate(predictions):
            entropy = -np.sum(pred * np.log(pred + 1e-10))
            analysis['prediction_entropy'].append(entropy)
        
        # Estat√≠sticas de confian√ßa por classe
        for class_id in range(self.num_classes):
            class_confidences = predictions[:, class_id]
            analysis['confidence_distribution'][class_id] = {
                'mean': float(np.mean(class_confidences)),
                'std': float(np.std(class_confidences)),
                'max': float(np.max(class_confidences)),
                'q95': float(np.percentile(class_confidences, 95))
            }
        
        # Calcular severidade do bias
        expected_frequency = 1.0 / self.num_classes  # Distribui√ß√£o uniforme esperada
        for class_id, frequency in analysis['class_frequency'].items():
            bias_ratio = frequency / expected_frequency
            analysis['bias_severity'][class_id] = bias_ratio
        
        self.bias_statistics = analysis
        return analysis
    
    def temperature_scaling(self, predictions: np.ndarray, temperature: float = 1.5) -> np.ndarray:
        """
        Aplica temperature scaling para calibrar probabilidades.
        
        Args:
            predictions: Predi√ß√µes originais
            temperature: Par√¢metro de temperatura (>1 reduz confian√ßa)
            
        Returns:
            Predi√ß√µes calibradas
        """
        # Aplicar temperature scaling
        scaled_logits = np.log(predictions + 1e-10) / temperature
        
        # Renormalizar para obter probabilidades
        exp_logits = np.exp(scaled_logits)
        calibrated_predictions = exp_logits / np.sum(exp_logits, axis=1, keepdims=True)
        
        return calibrated_predictions
    
    def label_smoothing(self, predictions: np.ndarray, smoothing: float = 0.1) -> np.ndarray:
        """
        Aplica label smoothing para reduzir overconfidence.
        
        Args:
            predictions: Predi√ß√µes originais
            smoothing: Fator de smoothing (0.1 = 10% de smoothing)
            
        Returns:
            Predi√ß√µes suavizadas
        """
        # Label smoothing formula: y_smooth = (1-Œ±) * y + Œ±/K
        uniform_dist = np.ones_like(predictions) / self.num_classes
        smoothed_predictions = (1 - smoothing) * predictions + smoothing * uniform_dist
        
        return smoothed_predictions
    
    def frequency_rebalancing(self, predictions: np.ndarray, target_distribution: Optional[np.ndarray] = None) -> np.ndarray:
        """
        Rebalanceia predi√ß√µes baseado na frequ√™ncia desejada das classes.
        
        Args:
            predictions: Predi√ß√µes originais
            target_distribution: Distribui√ß√£o alvo (padr√£o: uniforme)
            
        Returns:
            Predi√ß√µes rebalanceadas
        """
        if target_distribution is None:
            # Distribui√ß√£o uniforme
            target_distribution = np.ones(self.num_classes) / self.num_classes
        
        # Calcular frequ√™ncia atual
        current_frequencies = np.mean(predictions, axis=0)
        
        # Calcular fatores de corre√ß√£o
        correction_factors = target_distribution / (current_frequencies + 1e-10)
        
        # Aplicar corre√ß√£o
        corrected_predictions = predictions * correction_factors
        
        # Renormalizar
        corrected_predictions = corrected_predictions / np.sum(corrected_predictions, axis=1, keepdims=True)
        
        return corrected_predictions
    
    def confidence_thresholding(self, predictions: np.ndarray, confidence_threshold: float = 0.7) -> np.ndarray:
        """
        Aplica thresholding baseado em confian√ßa para reduzir predi√ß√µes incertas.
        
        Args:
            predictions: Predi√ß√µes originais
            confidence_threshold: Limiar m√≠nimo de confian√ßa
            
        Returns:
            Predi√ß√µes filtradas por confian√ßa
        """
        max_confidences = np.max(predictions, axis=1)
        
        # Criar m√°scara para predi√ß√µes com alta confian√ßa
        high_confidence_mask = max_confidences >= confidence_threshold
        
        # Para predi√ß√µes de baixa confian√ßa, usar distribui√ß√£o uniforme
        uniform_predictions = np.ones_like(predictions) / self.num_classes
        
        # Combinar predi√ß√µes
        thresholded_predictions = np.where(
            high_confidence_mask[:, np.newaxis],
            predictions,
            uniform_predictions
        )
        
        return thresholded_predictions
    
    def ensemble_correction(self, predictions_list: List[np.ndarray], weights: Optional[List[float]] = None) -> np.ndarray:
        """
        Combina m√∫ltiplas corre√ß√µes usando ensemble.
        
        Args:
            predictions_list: Lista de predi√ß√µes corrigidas
            weights: Pesos para cada m√©todo (padr√£o: uniforme)
            
        Returns:
            Predi√ß√µes ensemble
        """
        if weights is None:
            weights = [1.0 / len(predictions_list)] * len(predictions_list)
        
        # Normalizar pesos
        weights = np.array(weights)
        weights = weights / np.sum(weights)
        
        # Combinar predi√ß√µes
        ensemble_predictions = np.zeros_like(predictions_list[0])
        for pred, weight in zip(predictions_list, weights):
            ensemble_predictions += weight * pred
        
        return ensemble_predictions
    
    def class_specific_correction(self, predictions: np.ndarray, class_corrections: Dict[int, float]) -> np.ndarray:
        """
        Aplica corre√ß√µes espec√≠ficas para classes problem√°ticas.
        
        Args:
            predictions: Predi√ß√µes originais
            class_corrections: Dict com fatores de corre√ß√£o por classe
            
        Returns:
            Predi√ß√µes com corre√ß√µes espec√≠ficas
        """
        corrected_predictions = predictions.copy()
        
        for class_id, correction_factor in class_corrections.items():
            if class_id < self.num_classes:
                corrected_predictions[:, class_id] *= correction_factor
        
        # Renormalizar
        corrected_predictions = corrected_predictions / np.sum(corrected_predictions, axis=1, keepdims=True)
        
        return corrected_predictions
    
    def adaptive_bias_correction(self, predictions: np.ndarray, signal_quality: Optional[np.ndarray] = None) -> np.ndarray:
        """
        Aplica corre√ß√£o adaptativa baseada na qualidade do sinal.
        
        Args:
            predictions: Predi√ß√µes originais
            signal_quality: Scores de qualidade do sinal (0-1)
            
        Returns:
            Predi√ß√µes com corre√ß√£o adaptativa
        """
        if signal_quality is None:
            # Usar confian√ßa como proxy para qualidade
            signal_quality = np.max(predictions, axis=1)
        
        corrected_predictions = np.zeros_like(predictions)
        
        for i, (pred, quality) in enumerate(zip(predictions, signal_quality)):
            if quality > 0.8:  # Alta qualidade - corre√ß√£o m√≠nima
                alpha = 0.1
            elif quality > 0.5:  # Qualidade m√©dia - corre√ß√£o moderada
                alpha = 0.3
            else:  # Baixa qualidade - corre√ß√£o agressiva
                alpha = 0.5
            
            # Interpolar entre predi√ß√£o original e distribui√ß√£o uniforme
            uniform_pred = np.ones(self.num_classes) / self.num_classes
            corrected_predictions[i] = (1 - alpha) * pred + alpha * uniform_pred
        
        return corrected_predictions
    
    def create_comprehensive_correction(self, predictions: np.ndarray, 
                                      signal_quality: Optional[np.ndarray] = None) -> Dict[str, np.ndarray]:
        """
        Aplica m√∫ltiplas t√©cnicas de corre√ß√£o e retorna todas as variantes.
        
        Args:
            predictions: Predi√ß√µes originais
            signal_quality: Scores de qualidade do sinal
            
        Returns:
            Dicion√°rio com diferentes vers√µes corrigidas
        """
        corrections = {}
        
        # 1. Temperature scaling
        corrections['temperature_scaled'] = self.temperature_scaling(predictions, temperature=1.5)
        
        # 2. Label smoothing
        corrections['label_smoothed'] = self.label_smoothing(predictions, smoothing=0.1)
        
        # 3. Frequency rebalancing
        corrections['frequency_rebalanced'] = self.frequency_rebalancing(predictions)
        
        # 4. Confidence thresholding
        corrections['confidence_thresholded'] = self.confidence_thresholding(predictions, confidence_threshold=0.7)
        
        # 5. Corre√ß√£o espec√≠fica para classe 46 (RAO/RAE)
        class_corrections = {46: 0.3}  # Reduzir significativamente classe 46
        corrections['class_specific'] = self.class_specific_correction(predictions, class_corrections)
        
        # 6. Corre√ß√£o adaptativa
        corrections['adaptive'] = self.adaptive_bias_correction(predictions, signal_quality)
        
        # 7. Ensemble de m√∫ltiplas corre√ß√µes
        ensemble_methods = [
            corrections['temperature_scaled'],
            corrections['frequency_rebalanced'],
            corrections['class_specific']
        ]
        corrections['ensemble'] = self.ensemble_correction(ensemble_methods, weights=[0.4, 0.3, 0.3])
        
        # 8. Corre√ß√£o conservadora (para pesquisa cl√≠nica)
        conservative_methods = [
            corrections['label_smoothed'],
            corrections['confidence_thresholded']
        ]
        corrections['conservative'] = self.ensemble_correction(conservative_methods, weights=[0.6, 0.4])
        
        return corrections
    
    def evaluate_correction_quality(self, original_predictions: np.ndarray, 
                                   corrected_predictions: np.ndarray,
                                   true_labels: Optional[np.ndarray] = None) -> Dict[str, float]:
        """
        Avalia a qualidade da corre√ß√£o aplicada.
        
        Args:
            original_predictions: Predi√ß√µes originais
            corrected_predictions: Predi√ß√µes corrigidas
            true_labels: Labels verdadeiros (opcional)
            
        Returns:
            M√©tricas de qualidade da corre√ß√£o
        """
        metrics = {}
        
        # Entropia m√©dia (diversidade)
        original_entropy = np.mean([-np.sum(p * np.log(p + 1e-10)) for p in original_predictions])
        corrected_entropy = np.mean([-np.sum(p * np.log(p + 1e-10)) for p in corrected_predictions])
        
        metrics['entropy_improvement'] = corrected_entropy - original_entropy
        
        # Distribui√ß√£o de classes
        original_dist = np.mean(original_predictions, axis=0)
        corrected_dist = np.mean(corrected_predictions, axis=0)
        
        # Uniformidade da distribui√ß√£o (menor = mais uniforme)
        metrics['original_uniformity'] = np.std(original_dist)
        metrics['corrected_uniformity'] = np.std(corrected_dist)
        metrics['uniformity_improvement'] = metrics['original_uniformity'] - metrics['corrected_uniformity']
        
        # Bias na classe 46
        metrics['original_class_46_bias'] = original_dist[46] if len(original_dist) > 46 else 0
        metrics['corrected_class_46_bias'] = corrected_dist[46] if len(corrected_dist) > 46 else 0
        metrics['class_46_bias_reduction'] = metrics['original_class_46_bias'] - metrics['corrected_class_46_bias']
        
        # Se temos labels verdadeiros, calcular m√©tricas de performance
        if true_labels is not None:
            original_accuracy = np.mean(np.argmax(original_predictions, axis=1) == true_labels)
            corrected_accuracy = np.mean(np.argmax(corrected_predictions, axis=1) == true_labels)
            
            metrics['original_accuracy'] = original_accuracy
            metrics['corrected_accuracy'] = corrected_accuracy
            metrics['accuracy_change'] = corrected_accuracy - original_accuracy
        
        return metrics
    
    def generate_correction_report(self, predictions: np.ndarray, 
                                 corrected_predictions_dict: Dict[str, np.ndarray],
                                 true_labels: Optional[np.ndarray] = None) -> str:
        """
        Gera relat√≥rio detalhado das corre√ß√µes aplicadas.
        
        Args:
            predictions: Predi√ß√µes originais
            corrected_predictions_dict: Dicion√°rio com predi√ß√µes corrigidas
            true_labels: Labels verdadeiros (opcional)
            
        Returns:
            Relat√≥rio em formato string
        """
        report = ["="*80]
        report.append("RELAT√ìRIO DE CORRE√á√ÉO DE BIAS - CARDIOAI PRO")
        report.append("="*80)
        report.append("")
        
        # An√°lise de bias original
        bias_analysis = self.analyze_bias_patterns(predictions, true_labels)
        
        report.append("üìä AN√ÅLISE DE BIAS ORIGINAL:")
        report.append(f"   Classes problem√°ticas: {bias_analysis['problematic_classes']}")
        report.append(f"   Entropia m√©dia: {np.mean(bias_analysis['prediction_entropy']):.3f}")
        
        if 46 in bias_analysis['class_frequency']:
            report.append(f"   Frequ√™ncia classe 46 (RAO/RAE): {bias_analysis['class_frequency'][46]:.1%}")
        report.append("")
        
        # Avalia√ß√£o de cada m√©todo de corre√ß√£o
        report.append("üîß AVALIA√á√ÉO DOS M√âTODOS DE CORRE√á√ÉO:")
        report.append("")
        
        for method_name, corrected_preds in corrected_predictions_dict.items():
            metrics = self.evaluate_correction_quality(predictions, corrected_preds, true_labels)
            
            report.append(f"üìã {method_name.upper()}:")
            report.append(f"   Melhoria de entropia: {metrics['entropy_improvement']:+.3f}")
            report.append(f"   Melhoria de uniformidade: {metrics['uniformity_improvement']:+.3f}")
            report.append(f"   Redu√ß√£o bias classe 46: {metrics['class_46_bias_reduction']:+.3f}")
            
            if 'accuracy_change' in metrics:
                report.append(f"   Mudan√ßa na acur√°cia: {metrics['accuracy_change']:+.3f}")
            
            report.append("")
        
        # Recomenda√ß√µes
        report.append("üí° RECOMENDA√á√ïES PARA PESQUISA:")
        report.append("   1. Use 'ensemble' para melhor balanceamento geral")
        report.append("   2. Use 'conservative' para pesquisa cl√≠nica cautelosa")
        report.append("   3. Use 'class_specific' para focar no bias da classe 46")
        report.append("   4. Sempre documente limita√ß√µes em publica√ß√µes")
        report.append("   5. Valide resultados com especialistas m√©dicos")
        report.append("")
        
        report.append("‚ö†Ô∏è  LIMITA√á√ïES:")
        report.append("   - Corre√ß√µes s√£o heur√≠sticas, n√£o substituem retreinamento")
        report.append("   - Bias populacional ainda presente")
        report.append("   - Valida√ß√£o cl√≠nica necess√°ria para uso m√©dico")
        report.append("   - Resultados podem variar entre popula√ß√µes")
        report.append("")
        
        report.append("="*80)
        
        return "\n".join(report)

def create_bias_corrector_for_ptbxl() -> BiasCorrector:
    """Cria corretor de bias espec√≠fico para modelo PTB-XL."""
    return BiasCorrector(num_classes=71)

# Exemplo de uso
def example_bias_correction():
    """Exemplo de como usar o corretor de bias."""
    
    # Simular predi√ß√µes com bias (classe 46 dominante)
    np.random.seed(42)
    n_samples = 1000
    n_classes = 71
    
    # Criar predi√ß√µes enviesadas
    predictions = np.random.dirichlet([1] * n_classes, n_samples)
    # Adicionar bias extremo na classe 46
    predictions[:, 46] *= 5
    predictions = predictions / np.sum(predictions, axis=1, keepdims=True)
    
    # Criar corretor
    corrector = create_bias_corrector_for_ptbxl()
    
    # Aplicar corre√ß√µes
    corrections = corrector.create_comprehensive_correction(predictions)
    
    # Gerar relat√≥rio
    report = corrector.generate_correction_report(predictions, corrections)
    print(report)
    
    return corrections

if __name__ == "__main__":
    example_bias_correction()